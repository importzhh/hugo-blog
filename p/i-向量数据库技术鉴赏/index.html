<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="前言 转载自b站建议结合原视频动画看，文字版主要节约再次观看时间 向量 这里有一些狗 熟悉犬类的朋友 应该能很快的区分出它们的品种 我们之所以能做到这一"><title>I: 向量数据库技术鉴赏</title><link rel=canonical href=https://blog.importzhh.me/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/><link rel=stylesheet href=/scss/style.min.0d8902b26558cddb5286ea49f2a7aadd5761ed898547e29e5ab572d8c0619ba6.css><meta property="og:title" content="I: 向量数据库技术鉴赏"><meta property="og:description" content="前言 转载自b站建议结合原视频动画看，文字版主要节约再次观看时间 向量 这里有一些狗 熟悉犬类的朋友 应该能很快的区分出它们的品种 我们之所以能做到这一"><meta property="og:url" content="https://blog.importzhh.me/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/"><meta property="og:site_name" content="importzhh的小破站"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="vectordatabase"><meta property="article:published_time" content="2023-08-21T22:05:47+08:00"><meta property="article:modified_time" content="2023-08-21T22:05:47+08:00"><meta name=twitter:title content="I: 向量数据库技术鉴赏"><meta name=twitter:description content="前言 转载自b站建议结合原视频动画看，文字版主要节约再次观看时间 向量 这里有一些狗 熟悉犬类的朋友 应该能很快的区分出它们的品种 我们之所以能做到这一"><link rel="shortcut icon" href=/favicon.ico></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_huce6e906a97de2553354850eae15a0392_8624_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a>
<span class=emoji>🍥</span></figure><div class=site-meta><h1 class=site-name><a href=/>importzhh的小破站</a></h1><h2 class=site-description>实事求是 思危思退思变</h2></div></header><ol class=social-menu><li><a href=https://github.com/importzhh target=_blank title=GitHub rel=me><svg width="800" height="800" viewBox="-1.65 0 259.3 259.3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" preserveAspectRatio="xMidYMid"><g><path fill="#9edcf2" d="M200.9 199.8c0 13.9-32.2 25.1-71.9 25.1-39.7.0-71.9-11.3-71.9-25.1.0-13.9 32.2-25.1 71.9-25.1C168.7 174.7 200.9 185.9 200.9 199.8zm0 0"/><g><defs><path id="SVGID_1_" d="M98.1 244.8c1.6 7.5 5.5 11.9 9.4 14.5h41.1c5-3.4 10.1-9.8 10.1-21.8v-31s.6-7.7 7.7-10.2c0 0 4.1-2.9-.3-4.5.0.0-19.5-1.6-19.5 14.4v23.6s.8 8.7-3.8 12.3v-29.2s.3-9.3 5.1-12.8c0 0 3.2-5.7-3.8-4.2.0.0-13.4 1.9-14 17.6l-.3 30h-3.2l-.3-30c-.6-15.6-14-17.6-14-17.6-7-1.6-3.8 4.2-3.8 4.2 4.8 3.5 5.1 12.8 5.1 12.8v29.5c-4.6-3.3-3.8-12.6-3.8-12.6v-23.6c0-16-19.5-14.4-19.5-14.4-4.5 1.6-.3 4.5-.3 4.5 7 2.6 7.7 10.2 7.7 10.2v21.7L98.1 244.8z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" overflow="visible"/></clipPath><path clip-path="url(#SVGID_2_)" fill="#7dbce7" d="M200.9 199.8c0 13.9-32.2 25.1-71.9 25.1-39.7.0-71.9-11.3-71.9-25.1.0-13.9 32.2-25.1 71.9-25.1C168.7 174.7 200.9 185.9 200.9 199.8zm0 0"/></g><path fill="#9edcf2" d="M46.9 125.9l-2.1 7.2s-.5 2.6 1.9 3.1c2.6-.1 2.4-2.5 2.2-3.2L46.9 125.9zm0 0"/><path fill="#010101" d="M255.8 95.6l.2-.9c-21.1-4.2-42.7-4.3-55.8-3.7 2.1-7.7 2.8-16.7 2.8-26.6.0-14.3-5.4-25.7-14-34.3 1.5-4.9 3.5-15.8-2-29.7.0.0-9.8-3.1-32.1 11.8-8.7-2.2-18-3.3-27.3-3.3-10.2.0-20.5 1.3-30.2 3.9C74.4-2.9 64.3.3 64.3.3c-6.6 16.5-2.5 28.8-1.3 31.8-7.8 8.4-12.5 19.1-12.5 32.2.0 9.9 1.1 18.8 3.9 26.5-13.2-.5-34-.3-54.4 3.8l.2.9c20.4-4.1 41.4-4.2 54.5-3.7.6 1.6 1.3 3.2 2 4.7-13 .4-35.1 2.1-56.3 8.1l.3.9c21.4-6 43.7-7.6 56.6-8 7.8 14.4 23 23.8 50.2 26.7-3.9 2.6-7.8 7-9.4 14.5-5.3 2.5-21.9 8.7-31.9-8.5.0.0-5.6-10.2-16.3-11 0 0-10.4-.2-.7 6.5.0.0 6.9 3.3 11.7 15.6.0.0 6.3 21 36.4 14.2V177s-.6 7.7-7.7 10.2c0 0-4.2 2.9.3 4.5.0.0 19.5 1.6 19.5-14.4v-23.6s-.8-9.4 3.8-12.6v38.8s-.3 9.3-5.1 12.8c0 0-3.2 5.7 3.8 4.2.0.0 13.4-1.9 14-17.6l.3-39.3h3.2l.3 39.3c.6 15.6 14 17.6 14 17.6 7 1.6 3.8-4.2 3.8-4.2-4.8-3.5-5.1-12.8-5.1-12.8v-38.5c4.6 3.6 3.8 12.3 3.8 12.3v23.6c0 16 19.5 14.4 19.5 14.4 4.5-1.6.3-4.5.3-4.5-7-2.6-7.7-10.2-7.7-10.2v-31c0-12.1-5.1-18.5-10.1-21.8 29-2.9 42.9-12.2 49.3-26.8 12.7.3 35.6 1.9 57.4 8.1l.3-.9c-21.7-6.1-44.4-7.7-57.3-8.1.6-1.5 1.1-3 1.6-4.6C212.9 91.4 234.6 91.4 255.8 95.6zm0 0"/><path fill="#f5ccb3" d="M174.6 63.7c6.2 5.7 9.9 12.5 9.9 19.8.0 34.4-25.6 35.3-57.2 35.3S70.1 114 70.1 83.5c0-7.3 3.6-14.1 9.8-19.7 10.3-9.4 27.7-4.4 47.4-4.4 19.7.0 37-5.1 47.3 4.3zm0 0"/><path fill="#fff" d="M108.3 85.3c0 9.5-5.3 17.1-11.9 17.1-6.6.0-11.9-7.7-11.9-17.1.0-9.5 5.3-17.1 11.9-17.1C103 68.1 108.3 75.8 108.3 85.3zm0 0"/><path fill="#af5c51" d="M104.5 85.5c0 6.3-3.6 11.4-7.9 11.4-4.4.0-7.9-5.1-7.9-11.4.0-6.3 3.6-11.4 7.9-11.4S104.5 79.2 104.5 85.5zm0 0"/><path fill="#fff" d="M172.2 85.3c0 9.5-5.3 17.1-11.9 17.1s-11.9-7.7-11.9-17.1c0-9.5 5.3-17.1 11.9-17.1C166.8 68.1 172.2 75.8 172.2 85.3zm0 0"/><path fill="#af5c51" d="M168.3 85.5c0 6.3-3.6 11.4-7.9 11.4-4.4.0-7.9-5.1-7.9-11.4.0-6.3 3.6-11.4 7.9-11.4C164.8 74.1 168.3 79.2 168.3 85.5zm0 0"/><path fill="#af5c51" d="M130.5 100.5c0 1.6-1.3 3-3 3-1.6.0-3-1.3-3-3s1.3-3 3-3c1.59999999999999.0 3 1.3 3 3zm0 0"/><path fill="#af5c51" d="M120.6 108c-.2-.5.1-1 .6-1.2s1 .1 1.2.6c.8 2.2 2.8 3.6 5.1 3.6s4.3-1.5 5.1-3.6c.2-.5.7-.8 1.2-.6s.8.7.6 1.2c-1 2.9-3.8 4.9-6.9 4.9C124.4 112.9 121.6 110.9 120.6 108zm0 0"/><path fill="#c4e5d9" d="M54.5 121.6c0 .8-.9 1.4-2.1 1.4-1.1.0-2.1-.6-2.1-1.4.0-.8.9-1.4 2.1-1.4C53.6 120.2 54.5 120.8 54.5 121.6zm0 0"/><path fill="#c4e5d9" d="M60.3 124.8c0 .8-.9 1.4-2.1 1.4-1.1.0-2.1-.6-2.1-1.4.0-.8.9-1.4 2.1-1.4C59.4 123.4 60.3 124 60.3 124.8zm0 0"/><path fill="#c4e5d9" d="M63.8 129c0 .8-.9 1.4-2.1 1.4-1.1.0-2.1-.6-2.1-1.4s.9-1.4 2.1-1.4C62.9 127.5 63.8 128.2 63.8 129zm0 0"/><path fill="#c4e5d9" d="M67 133.8c0 .8-.9 1.4-2.1 1.4-1.1.0-2.1-.6-2.1-1.4s.9-1.4 2.1-1.4C66.1 132.3 67 133 67 133.8zm0 0"/><path fill="#c4e5d9" d="M70.5 138.2c0 .8-.9 1.4-2.1 1.4-1.1.0-2.1-.6-2.1-1.4s.9-1.4 2.1-1.4C69.6 136.8 70.5 137.4 70.5 138.2zm0 0"/><path fill="#c4e5d9" d="M75.3 142.1c0 .8-.9 1.4-2.1 1.4-1.1.0-2.1-.6-2.1-1.4s.9-1.4 2.1-1.4C74.4 140.6 75.3 141.3 75.3 142.1zm0 0"/><path fill="#c4e5d9" d="M82 144.6c0 .8-.9 1.4-2.1 1.4-1.1.0-2.1-.6-2.1-1.4s.9-1.4 2.1-1.4S82 143.8 82 144.6zm0 0"/><path fill="#c4e5d9" d="M88.7 144.6c0 .8-.9 1.4-2.1 1.4-1.1.0-2.1-.6-2.1-1.4s.9-1.4 2.1-1.4S88.7 143.8 88.7 144.6zm0 0"/><path fill="#c4e5d9" d="M95.5 143.5c0 .8-.9 1.4-2.1 1.4-1.1.0-2.1-.6-2.1-1.4s.9-1.4 2.1-1.4C94.5 142.1 95.5 142.7 95.5 143.5zm0 0"/></g></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/links/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg><span>Links</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>暗色模式</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><ol><li><a href=#前言>前言</a></li><li><a href=#向量>向量</a></li><li><a href=#词向量>词向量</a></li><li><a href=#向量数据库>向量数据库</a></li><li><a href=#最近邻搜索算法>最近邻搜索算法</a></li><li><a href=#内存开销问题>内存开销问题</a></li><li><a href=#有损压缩方法-乘积量化-product-quantization>有损压缩方法 乘积量化 Product Quantization</a></li><li><a href=#图像压缩的例子>图像压缩的例子</a></li><li><a href=#向量量化>向量量化</a></li><li><a href=#量化的内存开销>量化的内存开销</a></li><li><a href=#基量化算法>基量化算法</a></li><li><a href=#nsw算法>NSW算法</a></li><li><a href=#向量数据库的功能>向量数据库的功能</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/chatgpt/>chatgpt</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/>I: 向量数据库技术鉴赏</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Aug 21, 2023</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>阅读时长: 12 分钟</time></div></footer></div></header><section class=article-content><h3 id=前言>前言</h3><p>转载自b站建议结合原视频动画看，文字版主要节约再次观看时间<div class=video-wrapper><iframe src="https://player.bilibili.com/player.html?as_wide=1&amp;high_quality=1&amp;page=1&bvid=BV11a4y1c7SW" scrolling=no frameborder=no framespacing=0 allowfullscreen></iframe></div></p><h3 id=向量>向量</h3><p><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_21.58.17.png width=1586 height=1002 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_21.58.17_hu9a8313af0e5f451c020e333caf1f5e16_2300103_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_21.58.17_hu9a8313af0e5f451c020e333caf1f5e16_2300103_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=158 data-flex-basis=379px>
这里有一些狗 熟悉犬类的朋友 应该能很快的区分出它们的品种</p><p>我们之所以能做到这一点</p><p>是因为我们会从不同的角度来观察它们的特征 比如体型的大小</p><p><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.03.36.png width=2652 height=444 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.03.36_hu3ef7a611d700b04c95fb7013ade2553e_1369660_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.03.36_hu3ef7a611d700b04c95fb7013ade2553e_1369660_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=597 data-flex-basis=1433px>
如果我们用一个坐标轴来表示这个特征 这些狗将落在不同的坐标<br>然而单纯依靠体型这一个特征还不够 比如金毛和拉布拉多的体型就十分的接近</p><p><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.04.07.png width=2734 height=1272 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.04.07_huddc40a6d0ccdfe29c2b38a61ef68c558_4324591_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.04.07_huddc40a6d0ccdfe29c2b38a61ef68c558_4324591_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=214 data-flex-basis=515px>
所以需要继续观察其他的特征 比如毛发的长短 我们再建立一个坐标轴 这样就区分开了金毛和拉布拉多<br>现在每只狗对应一个二维坐标点</p><p>但这仍然不能够很好地区分 德国牧羊犬和挪威纳犬 因为无论是体型还是毛发的长短 他们都十分的接近</p><p><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.04.27.png width=2544 height=1672 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.04.27_hu9241a4f67588398fe5a8524d5dd162a5_5454431_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.04.27_hu9241a4f67588398fe5a8524d5dd162a5_5454431_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=152 data-flex-basis=365px>
所以我们需要继续从更多的角度来观察 比如鼻子的长短 再建立一个坐标轴 于是这两个全轴也被区分开来 现在每只狗对应一个三维的坐标点<br>我们还可以有更多的角度 比如眼睛的大小</p><p><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.09.03.png width=1508 height=1530 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.09.03_huf0b4ffd0b7935a2eee452d1360b0b30b_3227030_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.09.03_huf0b4ffd0b7935a2eee452d1360b0b30b_3227030_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=98 data-flex-basis=236px>
虽然作为三维生物 我们不可能在四维空间作图 但在坐标点的数值上却很容易实现 这一点 继续向后追加就好<br>现在每只狗对应一个四维的坐标点<br>如果我们从更多的角度或者说维度 来观察一只狗的特征 比如腿的粗 毛发的卷曲 甚至是一些抽象的角度<br>比如服从性 攻击性等等等等 我们使用的维度越多 对狗的区分能力就越强 同时坐标点所在的空间维度也就越高</p><p>不仅是狗 实际上几乎所有的事情都可以被这样表达<br>可以是具象的山河日月鸟兽鱼虫 也可以是抽象的喜怒哀乐 悲欢离合</p><p>不同事物在不同的特征维度中有着不同的表现 或者说不同的数值<br>所以最终都会在在一个高维的特征空间中 对应着一个坐标点
只不过在这些更大的范围内 我们可能需要更高的特征维度<br>才能很好的对进行事物区分 可能几百几千乃至上万<br>但由于我们无法做出超过三维的图
所以接下来我们都是用二维坐标来讲解 你会发现这种表达事物的方式 有着很多美妙的特性</p><p>那些概念上更为接近的点 在空间中更为聚集</p><p>而那些概念上非常不同的点则距离很远</p><p>更进一步 如果以坐标原点为起点 这些坐标点为终点<br>我们知道 这就是我们熟悉的带有方向和大小的向量</p><p>而从向量的角度 这种表达方式甚至有了一定的推理能力<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.16.25.png width=2930 height=1658 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.16.25_hub4e3bdde2d8bd4f53c99d6f8a7478e52_7026850_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.16.25_hub4e3bdde2d8bd4f53c99d6f8a7478e52_7026850_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=176 data-flex-basis=424px>
比如警察的向量减去小偷的向量得到的结果向和猫的向量减去老鼠的结果向量十分的相似
这意味着猫和老鼠的关系 类似于警察和小偷的关系</p><p>用向量化的数据来表达概念 不得不说是一个非常好的想法</p><p>如果我们对图片进行向量化 那么就可以通过搜索相似的向量 实现图搜图的功能
如果对视频进行向量的话 就可以通过搜索相似的向量 实现相关视频的推荐<br>如果对商品进行向量的话 就可以通过搜索相似的向量 针对用户当前浏览的商品进行相关推荐<br>而如果对一个文本进行向量化 就能在一个智能问答系统 从根据用户当前的问题 找到一些已经解决过的相似的问题 以供参考</p><h3 id=词向量>词向量</h3><p><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.21.25.png width=2908 height=1684 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.21.25_hu9b850fe0a8e823bc43970c842a6a602b_5986076_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.21.25_hu9b850fe0a8e823bc43970c842a6a602b_5986076_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=172 data-flex-basis=414px>
说到文本类的数据 近些年来对词汇进行向量化 在自然语言处理领域得到了巨大意义<br>也就是所谓的<strong>词向量</strong><br>实际上语言作为概念的符号<br>你会发现一个训练恰当的词向量集合 将和其所指代的事物之间的向量集合 十分的接近<br>这很利于发现自然语言中所蕴含的实际概念</p><p>除了词向量以外<br>最近随着以chatgpt为代表的大语言模型的如火如荼<br>人们又发现了向量数据的一些妙用</p><p>如果我们把chatgpt的对话内容进行向量化 便可以用当前的对话<br>搜索到历史中最为相似的一些对话 也就是找到和当前对话最相关的记忆<br>而把这些最相关的记忆提示给模型 将极大地提高其输出的效果</p><h3 id=向量数据库>向量数据库</h3><p>最近几年 一种叫做向量数据库的产品 正趁着ai的热潮开始崭露头角<br>向量数据库的倡导者和创业者们 正是基于这样的一种设想 开始了他们的视野<br>伴随着大ai时代的到来 向量将成为一种重要的数据形式<br>而传统的数据库并不适合用来存储和检索 向量数据<br>因此我们需要一种专门设计的数据库来处理这些问题<br>这或许会成为未来数据层面的基础设施</p><p>和存储数据表 然后用查询语句进行精准搜索的传统数据库不同<br>向量数据库存储的是向量数据 而查询过程则是从库中搜索出和查询向量最为相似的一些向量 具有一定的模糊性</p><h3 id=最近邻搜索算法>最近邻搜索算法</h3><p>通过以上这些例子不难看出<br>向量数据的一个主要应用场景就是给定一个查询向量 然后从众多的向量中找到最为相似的一些<br>这就是所谓的<strong>最近邻问题</strong><br>而能实现这一点的则称之为最近邻搜索算法</p><p>一种最容易想到的方法可能就是<strong>暴力搜索</strong> 就是一路直接平推过去
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.26.21.png width=2718 height=1656 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.26.21_hua7864d71b7dd0aade84a0d1794383af4_5829166_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.26.21_hua7864d71b7dd0aade84a0d1794383af4_5829166_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=164 data-flex-basis=393px>
依次比较所有向量和查询向量的相似度 挑选出相似度最高的几个</p><p>比较两个向量的相似度的具体方法有许多<br>两个向量的夹角越小越相似 所以可以通过计算向量夹角的余弦值来判断<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.25.32.png width=1588 height=1416 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.25.32_hub780e93452d25a477624ff0cfd6b866e_421725_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.25.32_hub780e93452d25a477624ff0cfd6b866e_421725_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=112 data-flex-basis=269px>
再比如直接计算两个向量的欧式距离 距离越近越相似</p><p>显然如果库中的向量过多 这种毫无技术含量的暴力方法 将导致极高的搜索时间<br>但这种方法也有着其他方法 永远无法到达的一个好处 <strong>它的搜索质量是完美的</strong></p><p>因为它真的比较了每一个向量 所以如果库中数据规模较小 便你全部销量的时间可以接受</p><p><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.29.05.png width=2848 height=1462 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.29.05_hu840244a12a1497b88d43097554522695_4721372_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.29.05_hu840244a12a1497b88d43097554522695_4721372_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=194 data-flex-basis=467px>
这也不失为一种好的方法 然而实际应用中的数据规模往往都不会太小<br>所以我们必须找出一些方法进行优化 有一种朴素的想法<br>指出了优化的大致思路 我们可以用一个寻人的例子来说明<br>假如已经知道照片上的这个人在a城市 现在请你想一个办法把他找出来<br>就相当于去找a城市的每一个人逐一比较 这样一定能够找到<br>但要花费海量的时间 但我们通过他胸前的红领巾 就知道他是一名小学生<br>所以就可以把寻找的范围 缩小到a城市的所有小学 如此就有可能将千万级别的查找次数<br>降到只有几万的级别 所以对于向量的搜索问题<br>假如能够为查询向量先划定一个大致的范围再搜索岂不美哉</p><p>有一种称之为<strong>聚类</strong>的算法可以实现这一点</p><p>我们以最为流行的<strong>k-means聚类算法</strong>为例<br>很简单我们先选定一个想要分类的数量 比如四类 然后随机生成四个点 称之为聚类中心点
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.30.29.png width=2630 height=1638 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.30.29_huc9809625a67e2f742098d2a1aed9aa70_5547775_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.30.29_huc9809625a67e2f742098d2a1aed9aa70_5547775_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=160 data-flex-basis=385px>
然后这些向量和哪一个中心点 最近就被分为哪一类 再然后用当前被分为一类的向量 计算出一个平均的向量点
把对应的中心点的位置更新为这个平均点<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.31.36.png width=2780 height=1690 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.31.36_hu0a11c36cce152e33cb352f3bdf7b94ce_6029514_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.31.36_hu0a11c36cce152e33cb352f3bdf7b94ce_6029514_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=164 data-flex-basis=394px>
再判断每个向量点和哪一个中心点最近
重新分类 然后继续用同一类的向量点计算出一个平均点 把中心点更新过去 再次重新分类</p><p>如此反复 这个不断迭代的过程就称之为训练<br>最后这些中心点将趋于稳定或者说收敛 最终将这些向量分成了四类<br>如此在搜索的时候 只需要找出和查询向量最近的那个聚类中心<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.33.40.png width=2600 height=1666 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.33.40_hu938e47e3a5980f4c80427f22efc80568_5856808_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.33.40_hu938e47e3a5980f4c80427f22efc80568_5856808_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=156 data-flex-basis=374px>
搜索这个分类中的向量即可 也就实现了缩小搜索范围的目的</p><p>当然聚类的方法并不能保证 不会出现遗漏的问题<br>比如查询向量在这里<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.34.25.png width=2602 height=1648 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.34.25_hu954289fbe4f9b77c9dcaa742e09e89e5_5729568_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.34.25_hu954289fbe4f9b77c9dcaa742e09e89e5_5729568_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=157 data-flex-basis=378px>
他和这个分类的中心最近 但和它最近的向量 其实是在这个分类中<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.36.00.png width=2610 height=1506 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.36.00_hu6051b6280e4ee1a911f7a811bd076152_5390544_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.36.00_hu6051b6280e4ee1a911f7a811bd076152_5390544_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=173 data-flex-basis=415px>
有一些缓解这个问题的办法 比如我们增加聚类的数量 同时指定搜索多个最近的区域 减少遗漏<br>但只要是试图提高搜索的质量 基本上都会增加搜索的时间</p><p><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.37.20.png width=2592 height=1310 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.37.20_hu36d2f8706c07794b9fbbf8b41d51184f_4262630_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.37.20_hu36d2f8706c07794b9fbbf8b41d51184f_4262630_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=197 data-flex-basis=474px>
实际上速度和质量往往是一对难以调和的矛盾 而几乎所有的算法都是在这两个指标上</p><p>结合实际情况衡量的结果 所以现实就是 除了暴力搜索一定能够找到最近邻的一些向量以外
其他任何方法都不能保证这一点 而只能得到一些近似的结果 所以其实这些算法一般也被称之为近似最近邻算法<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.38.19.png width=2204 height=1086 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.38.19_huba06dd94afb3cccb2f7cc499e6cfd2cb_2937297_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.38.19_huba06dd94afb3cccb2f7cc499e6cfd2cb_2937297_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=202 data-flex-basis=487px>
除了聚类以外 减少搜索范围的方式还有很多</p><p>这里再介绍一种比较流行的基于哈希的方法
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.39.02.png width=1972 height=478 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.39.02_hu1293c192cd0141ab26a80c6c1b18bdb0_233437_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.39.02_hu1293c192cd0141ab26a80c6c1b18bdb0_233437_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=412 data-flex-basis=990px>
我们曾在md 的视频中介绍过哈希的概念 简单来说就是任何数据经过哈希函数计算之后 都会输出一个固定长度的哈希值
比如128位
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.41.20.png width=2642 height=836 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.41.20_huf86a52bb91fd979241bea3896593f9a4_2670785_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.41.20_huf86a52bb91fd979241bea3896593f9a4_2670785_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=316 data-flex-basis=758px></p><p>而且由于输入是任意的数据 而输出是固定长度的数 以有穷对无穷<br>根据鸽巢原理 必然会出现数据不同 但哈希值相同的情况 这也被称之为碰撞</p><p>通常情况下 哈希函数的设计一般力求减少这种碰撞的发生 但这里所构建的哈希函数却反其道而行<br>它力求增大发生碰撞的可能<br>因为哈希碰撞正是分组的依据 哈希值一样的向量被分到同一组 这些分组也被称之为桶
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.43.13.png width=2870 height=1448 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.43.13_hu8cf6ed605e935c91783f34c19a24f710_4927209_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.43.13_hu8cf6ed605e935c91783f34c19a24f710_4927209_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=198 data-flex-basis=475px></p><p>除了容易发生碰撞以外 这个哈希函数还要具备这样的一个特性<br>位置越近 或者说越相似的向量发生碰撞的概率越高 被分到同一个桶中的可能性越大<br>如此在查询的时候 只需要计算一下查询向量的哈希值 找到其所在的桶<br>再在这个桶中搜索就好了 因为和查询向量最相似的一些销量<br>大概率都在这个图 我们把具有这种特性的哈希函数 称之为<strong>位置敏感的哈希函数</strong></p><p>这样的哈希函数怎么实现呢 我们来看一种常用的手法
我们以a b c 个向量为例 首先随机生成一条直线 而且这条线区分正反两侧
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.44.42.png width=2216 height=1624 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.44.42_hu94e7adc7cd7b290278a02a9e2b644df4_4592383_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.44.42_hu94e7adc7cd7b290278a02a9e2b644df4_4592383_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=136 data-flex-basis=327px>
比如这边是正的一侧 这边是反的一侧 如果一个向量在这条线的正的一侧
那么他就是一 如果再反的一侧 那么就是零<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.45.25.png width=1990 height=1402 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.45.25_hu6e87c179379bad430461660828cd7e68_3545073_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.45.25_hu6e87c179379bad430461660828cd7e68_3545073_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=141 data-flex-basis=340px>
然后再随机生成一条直线<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.46.20.png width=2042 height=1394 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.46.20_hu8d092d86a0fbacea76b82a74e835b7f2_3579479_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.46.20_hu8d092d86a0fbacea76b82a74e835b7f2_3579479_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=146 data-flex-basis=351px>
同样正侧的向量是一 反侧的向量是零 如此这般我们随机的生成若干个这样的直线</p><p>每次都根据所在的正反侧得到一或者零 如果一共使用四条随机的直线<br>如此就为每个向量算出了四个零或者一 各自得到一个四位的二进制编码
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.46.58.png width=2076 height=1556 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.46.58_hu1bbd67edaa8d239100ea9403b98fd499_4107571_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.46.58_hu1bbd67edaa8d239100ea9403b98fd499_4107571_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=133 data-flex-basis=320px></p><p>现在我们来观察一下 这三个二进制编码的相似程度<br>很明显 ac这两个更近的向量的编码更为相似<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.48.12.png width=2310 height=1556 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.48.12_hu550184d8e2c67c82ccd0946ede4c7aa2_4470037_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.48.12_hu550184d8e2c67c82ccd0946ede4c7aa2_4470037_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=148 data-flex-basis=356px>
只有第三位不同 相似度高达3/4 而这个较远的b和ac的相似度都很低 一个是1/4 一个是零
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.49.02.png width=2038 height=1372 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.49.02_hucf590e5aeeb58f4ee64d1d428d76741f_3555526_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.49.02_hucf590e5aeeb58f4ee64d1d428d76741f_3555526_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=148 data-flex-basis=356px>
所以为什么向量越接近 得到的二进制编码就越相似呢<br>我们直观的来定性分析一下 在计算这四个二进制编码的某一位的时候<br>如果要让b和c的结果一样 那么这条线应该是这样的<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.51.11.png width=2028 height=1380 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.51.11_hua68aa4404bde0248d339f84ab92d6963_3377205_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.51.11_hua68aa4404bde0248d339f84ab92d6963_3377205_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=146 data-flex-basis=352px></p><p>当然也可以是这样<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.52.35.png width=2060 height=1360 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.52.35_hua84a5d1407d8559e8b14dc42f08aa7a1_3410996_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.52.35_hua84a5d1407d8559e8b14dc42f08aa7a1_3410996_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=151 data-flex-basis=363px>
但不论如何 一定要从ac和ab之间穿过去
同样如果要让a和c的结果一样 这条线应该从bc和ab之间穿过
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.53.23.png width=2010 height=1390 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.53.23_huf431a93c97a6afd806d1153b83982ffe_1464115_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.53.23_huf431a93c97a6afd806d1153b83982ffe_1464115_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=144 data-flex-basis=347px></p><p>我们忽略共同穿越的AB 直观上来看 b和c之间的宽度 要远远大于a和c之间的宽度<br>而我们的直线是随机生成的 所以从概率上来说 生成的直线从bc穿过的可能性<br>要比从ac穿过的要更大 所以在生成二进制编码的过程中 c更有可能和a一样而不是b
同样如果要让a和b的编码值一样 直线要穿过ac和bc 而如果要让a和c的结果一样<br>这条线应该从bc和ab之间穿过 忽略共同穿越的bc ac间的宽度也远小ab<br>所以a也是更可能和c一样 而不是b<br>所以这串二进制编码便可以作为向量的哈希值
而这个生成的过程 就是一种我们所找寻的哈希函数 因为它满足我们刚才说的两个要求
<strong>容易碰撞 而且越相似的向量越容易碰撞 以至于被分到同一个桶中</strong><br>当然这三个向量的哈希值并不完全相同 但如果我们再观察一个距离a更近的d<br>你就会发现d最后的二进制编码 或者说哈希值和a一样发生的碰撞<br>我们用四个向量 展示了这个方法的基本工作原理
而对于真实情况中的许多向量而言<br>每个向量通过这个哈希函数后 都会得到一串二进制编码的哈希值 而那些非常接近的<br>像那样的哈希值大概率是一样的 也就被分到了同一个桶中 对于更高维度的向量 道理也是一样的</p><p>比如三维 便可以使用三维空间中的一个随机平面 来做哈希函数的计算
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.55.31.png width=2252 height=1692 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.55.31_hu31aed84e43d44fc065da1945c259f7b3_4823787_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.55.31_hu31aed84e43d44fc065da1945c259f7b3_4823787_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=133 data-flex-basis=319px>
这个面也有正反正面的向量得到一 反面的向量得到零 若干个随机平面<br>自然也就得到了一串二进制编码的哈希值 如果是更高的维度 虽然我们做不出图形<br>但却可以理解 在这些更高维度中也存在着包围的超平面 同样也可以完成这样的哈希值生成</p><p>所以我们把这种方法称之为 <strong>随机超平面或者随机投影</strong> 当然正如我们所言<br>除了直接暴搜 任何试图减少搜索量的方法 方法都会在一定程度上降低搜索的质量</p><p>比如还是这四个向量 现在我们用九条随机直线 每个向量生成长度为九的二进制哈希编码
可能是这样的过程 ad两个比较近的点的哈希值一致 被分到了同一个桶中 这是比较理想的结果
但因为直线是随机的 我们把握不住 所以这个过程也有可能是这样的 在生成第六个编码的时候
这个直线真的就随机到了 从ad之间穿过 导致a和d的哈希编码的第六位不同 虽然我们说概率比较小
但毕竟是有可能发生的 最后a和d无法进入同一个痛 所以一般会采用一种分段的措施 来改善这种情况
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.57.35.png width=2040 height=1348 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.57.35_hudb79a1bc169877e5639aacdbe252585d_3598173_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.57.35_hudb79a1bc169877e5639aacdbe252585d_3598173_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=151 data-flex-basis=363px>
比如现在我们把这些二进制哈希值分成三段 然后独立的对这些片段进行分头 如此
虽然d的第二个片段被分到了不同的桶中 但第个片段却被分到了同一个桶 我们可以采用只要匹配一个片段<br><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.58.40.png width=2774 height=1570 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.58.40_hubdbb1e5807d47e2cdd98bc07b472b514_5587889_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.58.40_hubdbb1e5807d47e2cdd98bc07b472b514_5587889_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=176 data-flex-basis=424px>
就将其作为候选项的策略 合理的扩充更多的搜索范围 你会发现在这种分段的措施下 a和c的第二段也被分到了同一个桶中
两者由此成为了相似向量的候选项 因为他们比较接近 这是一种合理的扩充 而b则没有任何一个段和其他向量对应的段<br>被分到同一个桶中 因为它们距离很远 这很合理</p><p><img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.59.54.png width=1512 height=1000 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.59.54_hub56861a3cd9762e325bf8226a4846964_1945258_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_22.59.54_hub56861a3cd9762e325bf8226a4846964_1945258_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=151 data-flex-basis=362px>
在上集中，我们简单介绍了一些提升搜索速度的方法，通过减少搜索范围来实现。但是对于海量的向量数据来说，除了搜索速度，内存开销也是一个巨大的挑战。</p><h3 id=内存开销问题>内存开销问题</h3><p>举个例子，假设向量的维度是128，每个维度的值是一个32位浮点数，那么一个向量占用的内存就是512字节。如果数据库中有1000万个向量，总共占用的内存就是大约4.77GB。在实际应用中，上千维甚至上亿维的向量数量并不罕见，所以内存开销问题是非常严重的。</p><h3 id=有损压缩方法-乘积量化-product-quantization>有损压缩方法 乘积量化 Product Quantization</h3><p>每个向量都对应着一个有用的记录，所以无法通过删除向量来节省内存。唯一的选择就是降低每个向量本身的大小。
一种方法是使用k-means聚类算法，将相邻且有一定聚集性的向量分为一类，并用聚类中心（也叫质心）来代替该类中的其他向量。这种方法实际上是一种有损压缩的方法。
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_23.07.32.png width=2386 height=1660 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_23.07.32_hu8c8b2c91d430a31a4fc0bd50f50946f2_3376277_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_23.07.32_hu8c8b2c91d430a31a4fc0bd50f50946f2_3376277_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=143 data-flex-basis=344px></p><h3 id=图像压缩的例子>图像压缩的例子</h3><p>举个图片的例子来说明，图片由像素点组成，每个像素点有RGB三个数值，可以将一个像素点看作是一个三维空间中的向量点。
通过聚类算法，在像素空间中将所有像素点替换为所在类别的质心点，可以实现图片的压缩。虽然质量有所下降，但仍然保留了原图的样貌。</p><h3 id=向量量化>向量量化</h3><p>类似地，对于向量数据，可以使用向量量化的方法来降低内存开销。将每个向量用编码值来表示，然后将编码值和对应的质心记录下来，形成一个码本。
每次使用某个向量时，通过编码值从码本中找到对应的质心，再恢复出原始向量的具体值。虽然向量已经不再是原来的样子，但问题不大，因为量化过程仍然保留了一些原始信息。
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_23.10.10.png width=2740 height=1452 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_23.10.10_hua6b426d6aa29e97bf49efd49ee57eac4_5264463_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_23.10.10_hua6b426d6aa29e97bf49efd49ee57eac4_5264463_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=188 data-flex-basis=452px></p><h3 id=量化的内存开销>量化的内存开销</h3><p>量化后的向量占用的内存开销确实降低了，但是量化过程会产生一个额外的码本，这会增加内存开销。
随着数据量的增大，数据可能越来越稀疏，聚类的效果如果需要得到保证，可能需要的聚类质心也就越多。
在低维向量中，这个开销可能不明显，但在高维向量中，这个开销会变得非常大。为了保证量化质量，可能需要非常大的聚类数量，这被称为维度灾难问题。</p><h3 id=基量化算法>基量化算法</h3><p>为了解决维度灾难问题，可以将高维向量分割成低维子向量，然后在子向量上进行独 立的量化。将子向量的量化编码值合并在一起，就得到了原始向量的最终量化编码值。
这种方法被称为基量化算法（PQ）。通过基量化，可以大大减少内存开销。
<img src=/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_23.15.16.png width=2936 height=1660 srcset="/p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_23.15.16_hu51312b9bee85277b3c1cc61b4b0ea717_5859420_480x0_resize_box_3.png 480w, /p/i-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF%E9%89%B4%E8%B5%8F/iShot_2023-08-31_23.15.16_hu51312b9bee85277b3c1cc61b4b0ea717_5859420_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=176 data-flex-basis=424px>
Product quantization for nearest neighbor searchPQ原始论文:基于(乘)积量化的近邻搜索</p><h3 id=nsw算法>NSW算法</h3><p>德劳内三角剖分法 Delaunay triangulation algorithm
NSW（Navigating Spreading-out Walk) 是一种基于图结构的近似最近邻算法。通过建立图结构，可以快速导航到目标节点，并通过精细化的搜索找到最相似的向量。
NSW算法的核心思想是先粗略搜索，再精细搜索。为了改善NSW算法的性能，可以使用HN-SW算法，它在NSW算法的基础上添加了多层结构，实现了由粗到细的搜索过程。</p><p>向量所有的点都先拿出来 在开始建立点之间的关系的时候，由于数据量较少，因此很稀疏（很容易演化成点之间的长连接），
随着数据的增加，点之间的联系会越来越密集。通过长连接快速到达点 再通过短连接细化到具体的点数据上。</p><p>Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs
使用分层导航小世界的高效且健壮的近似最近邻搜索</p><h3 id=向量数据库的功能>向量数据库的功能</h3><p>向量数据库除了支持近似最近邻算法，还需要具备传统数据库的功能，如简单易用的访问接口、访问控制、权限管理、审计功能、数据备份等。
此外，向量数据库还需要具备多节点、容错性、监控和追踪功能，以满足大规模数据和访问量的需求。</p><p>在大AI时代的开端，向量数据库是一个具有广阔前景的领域，但也面临着工程上的挑战。一个可用的向量数据库产品需要解决诸多细节问题，并综合各种算法和功能，以提供高效、可靠的服务。</p></section><footer class=article-footer><section class=article-tags><a href=/tags/vectordatabase/>vectordatabase</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css integrity="sha256-J+iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js integrity="sha256-InsNdER1b2xUewP+pKCUJpkhiqwHgqiPXDlIk7GzBu4=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI=" crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/iii-%E5%9F%BA%E4%BA%8E%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE%E4%BD%BF%E7%94%A8langchain%E6%9E%84%E5%BB%BA%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA/><div class=article-details><h2 class=article-title>III: 基于私有数据使用LangChain构建聊天机器人</h2></div></a></article><article><a href=/p/ii-%E5%9F%BA%E4%BA%8Elangchain%E7%9A%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B8%8B/><div class=article-details><h2 class=article-title>II: 基于LangChain的大语言模型应用开发(下)</h2></div></a></article><article><a href=/p/i-%E5%9F%BA%E4%BA%8Elangchain%E7%9A%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B8%8A/><div class=article-details><h2 class=article-title>I: 基于LangChain的大语言模型应用开发(上)</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2023 importzhh的小破站</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.16.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>